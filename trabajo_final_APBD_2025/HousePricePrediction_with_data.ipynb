{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73561d26",
   "metadata": {},
   "source": [
    "# Predicción del precio de viviendas con PySpark\n",
    "Este notebook utiliza Apache Spark para construir un modelo de regresión que predice el precio de viviendas usando el dataset de Kaggle 'House Prices - Advanced Regression Techniques'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbf2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import pyspark.sql.functions as F\n",
    "from math import sqrt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"HousePricePrediction\").getOrCreate()\n",
    "\n",
    "train_df = spark.read.csv(\"data/train.csv\", header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(\"data/test.csv\", header=True, inferSchema=True)\n",
    "\n",
    "train_df.printSchema()\n",
    "train_df.select(\"SalePrice\").describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "\n",
    "missing_values = train_df.select([\n",
    "    count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in train_df.columns\n",
    "])\n",
    "missing_values.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c, t in train_df.dtypes if t in ['int', 'double'] and c != 'SalePrice']\n",
    "cat_cols = [c for c, t in train_df.dtypes if t == 'string']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy=\"median\", inputCols=num_cols, outputCols=[c + \"_imp\" for c in num_cols])\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"keep\") for c in cat_cols]\n",
    "encoders = [OneHotEncoder(inputCol=c + \"_idx\", outputCol=c + \"_ohe\") for c in cat_cols]\n",
    "\n",
    "feature_cols = [c + \"_imp\" for c in num_cols] + [c + \"_ohe\" for c in cat_cols]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"SalePrice\")\n",
    "\n",
    "pipeline_lr = Pipeline(stages=indexers + encoders + [imputer, assembler, lr])\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "cv_lr = CrossValidator(estimator=pipeline_lr,\n",
    "                       estimatorParamMaps=paramGrid_lr,\n",
    "                       evaluator=evaluator_rmse,\n",
    "                       numFolds=5)\n",
    "\n",
    "lr_model = cv_lr.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81deb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"SalePrice\")\n",
    "\n",
    "pipeline_rf = Pipeline(stages=indexers + encoders + [imputer, assembler, rf])\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "cv_rf = CrossValidator(estimator=pipeline_rf,\n",
    "                       estimatorParamMaps=paramGrid_rf,\n",
    "                       evaluator=evaluator_rmse,\n",
    "                       numFolds=5)\n",
    "\n",
    "rf_model = cv_rf.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.transform(train_df)\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import Evaluator\n",
    "\n",
    "class RmsleEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol='prediction', targetCol='SalePrice'):        \n",
    "        super(RmsleEvaluator, self).__init__()\n",
    "        self.predictionCol = predictionCol\n",
    "        self.targetCol = targetCol\n",
    "\n",
    "    def _evaluate(self, dataset):\n",
    "        error = self.rmsle(dataset, self.predictionCol, self.targetCol)\n",
    "        print(\"RMSLE:\", error)\n",
    "        return error\n",
    "\n",
    "    def isLargerBetter(self):\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def rmsle(dataset, predictionCol, targetCol):\n",
    "        return sqrt(dataset.select(F.avg((F.log1p(dataset[targetCol]) - F.log1p(dataset[predictionCol])) ** 2)).first()[0])\n",
    "\n",
    "rmsle_eval = RmsleEvaluator()\n",
    "rmsle = rmsle_eval.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = rf_model.transform(test_df)\n",
    "final_predictions.select(\"Id\", \"prediction\") \\\n",
    "    .withColumnRenamed(\"prediction\", \"SalePrice\") \\\n",
    "    .toPandas().to_csv(\"data/submission2.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
